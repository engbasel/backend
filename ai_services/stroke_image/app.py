"""
NeuroAid Stroke Image Analysis Service
=======================================
REAL AI-powered stroke detection from CT/MRI scans.
This service uses the TRAINED Keras model for image analysis.

IMPORTANT: This service uses the TRAINED AI MODEL, NOT mock/rule-based analysis.
"""

import sys
import os

# Fix Windows encoding issues - MUST BE FIRST
if sys.platform == 'win32':
    import codecs
    if sys.stdout.encoding != 'utf-8':
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    if sys.stderr.encoding != 'utf-8':
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')
    os.environ['PYTHONIOENCODING'] = 'utf-8'

# Add the ai/stroke_image directory to Python path to load the AI model
stroke_image_ai_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..', 'ai', 'stroke_image'))
if stroke_image_ai_path not in sys.path:
    sys.path.insert(0, stroke_image_ai_path)

from flask import Flask, request, jsonify
from flask_cors import CORS
from datetime import datetime
import numpy as np
from PIL import Image
import io

app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "*"}})

# Load the REAL AI model
model = None
MODEL_LOADED = False
MODEL_PATH = os.path.join(stroke_image_ai_path, 'stroke_image.keras')

try:
    import tensorflow as tf

    if os.path.exists(MODEL_PATH):
        model = tf.keras.models.load_model(MODEL_PATH)
        MODEL_LOADED = True
        print(f"âœ… Stroke Image AI Model loaded successfully from: {MODEL_PATH}")
    else:
        print(f"âŒ Model file not found at: {MODEL_PATH}")
        print("âš ï¸  Service will return errors instead of mock responses")
except Exception as e:
    print(f"âŒ Failed to load Stroke Image AI Model: {e}")
    print("âš ï¸  Service will return errors instead of mock responses")

def preprocess_image(image_file):
    """
    Preprocess image for the trained Keras model

    Expected input: CT/MRI scan image
    Output: Preprocessed numpy array ready for model inference
    """
    try:
        # Read image
        image = Image.open(image_file)

        # Convert to RGB if necessary
        if image.mode != 'RGB':
            image = image.convert('RGB')

        # Resize to model's expected input size (adjust based on your model)
        # Common sizes: 224x224, 256x256, or 512x512
        target_size = (224, 224)  # Adjust if your model expects different size
        image = image.resize(target_size)

        # Convert to numpy array and normalize
        img_array = np.array(image).astype('float32')
        img_array = img_array / 255.0  # Normalize to [0, 1]

        # Add batch dimension
        img_array = np.expand_dims(img_array, axis=0)

        return img_array

    except Exception as e:
        raise Exception(f"Error preprocessing image: {str(e)}")

def interpret_prediction(prediction_value):
    """
    Interpret model prediction and return meaningful results

    Args:
        prediction_value: Raw model output (probability)

    Returns:
        result, confidence, findings
    """
    confidence = float(prediction_value)

    # Threshold-based classification
    if confidence > 0.7:
        result = 'abnormal'
        findings = [
            'âš ï¸ ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø¹Ù„Ø§Ù…Ø§Øª Ù…Ø­ØªÙ…Ù„Ø© Ù„Ù„Ø³ÙƒØªØ© Ø§Ù„Ø¯Ù…Ø§ØºÙŠØ©',
            'ØªÙˆØ¬Ø¯ Ù…Ù†Ø§Ø·Ù‚ ØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠØ© ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©',
            'ÙŠÙÙ†ØµØ­ Ø¨Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø·Ø¨ÙŠØ¨ Ø§Ù„Ù…Ø®ØªØµ ÙÙˆØ±Ø§Ù‹',
            'Ù‚Ø¯ ØªÙƒÙˆÙ† Ù‡Ù†Ø§Ùƒ Ø­Ø§Ø¬Ø© Ù„ÙØ­ÙˆØµØ§Øª Ø¥Ø¶Ø§ÙÙŠØ©',
            'Ø§Ù„ÙˆÙ‚Øª Ø¹Ø§Ù…Ù„ Ø­Ø§Ø³Ù… ÙÙŠ Ø¹Ù„Ø§Ø¬ Ø§Ù„Ø³ÙƒØªØ© Ø§Ù„Ø¯Ù…Ø§ØºÙŠØ©'
        ]
    elif confidence > 0.4:
        result = 'requires_review'
        findings = [
            'Ø§Ù„ØµÙˆØ±Ø© ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø© Ù…Ù† Ù‚Ø¨Ù„ Ø£Ø®ØµØ§Ø¦ÙŠ',
            'ØªÙˆØ¬Ø¯ Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ ØªÙ‚ÙŠÙŠÙ… Ø¯Ù‚ÙŠÙ‚',
            'ÙŠÙÙ†ØµØ­ Ø¨Ø¥Ø¬Ø±Ø§Ø¡ ÙØ­ÙˆØµØ§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„ØªØ£ÙƒØ¯',
            'Ø§Ø³ØªØ´Ø± Ø·Ø¨ÙŠØ¨ Ø§Ù„Ø£Ø¹ØµØ§Ø¨ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙ‚ÙŠÙŠÙ… Ø´Ø§Ù…Ù„'
        ]
    else:
        result = 'normal'
        findings = [
            'âœ… Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¹Ù„Ø§Ù…Ø§Øª ÙˆØ§Ø¶Ø­Ø© Ù„Ù„Ø³ÙƒØªØ© Ø§Ù„Ø¯Ù…Ø§ØºÙŠØ©',
            'Ø§Ù„ØµÙˆØ±Ø© ØªØ¨Ø¯Ùˆ Ø·Ø¨ÙŠØ¹ÙŠØ© Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù…',
            'Ø§Ø³ØªÙ…Ø± ÙÙŠ Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„Ø¯ÙˆØ±ÙŠØ© Ù…Ø¹ Ø·Ø¨ÙŠØ¨Ùƒ',
            'Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ù†Ù…Ø· Ø­ÙŠØ§Ø© ØµØ­ÙŠ Ù„Ù„ÙˆÙ‚Ø§ÙŠØ©'
        ]

    return result, confidence, findings

@app.route('/health', methods=['GET'])
def health():
    """Health check endpoint"""
    return jsonify({
        'status': 'OK' if MODEL_LOADED else 'ERROR',
        'service': 'NeuroAid Stroke Image Analysis Service',
        'ai_model_loaded': MODEL_LOADED,
        'model_path': MODEL_PATH if MODEL_LOADED else None,
        'timestamp': datetime.now().isoformat()
    })

@app.route('/analyze', methods=['POST'])
def analyze():
    """
    REAL AI Image Analysis endpoint - Uses trained Keras model

    Expected input:
    - multipart/form-data with 'image' field containing CT/MRI scan

    Returns: JSON with analysis results from the trained model
    """
    try:
        # Check if AI model is loaded
        if not MODEL_LOADED:
            return jsonify({
                'error': 'AI model not loaded',
                'message': 'The trained stroke image analysis model could not be loaded. Please check server configuration.',
                'details': f'Model file not found at: {MODEL_PATH}'
            }), 503

        # Check if image file is present
        if 'image' not in request.files:
            return jsonify({
                'error': 'No image file provided',
                'message': 'Please provide an image file in the request'
            }), 400

        image_file = request.files['image']

        if image_file.filename == '':
            return jsonify({
                'error': 'No image file selected',
                'message': 'Please select a valid image file'
            }), 400

        # Preprocess image for the model
        try:
            preprocessed_image = preprocess_image(image_file)
        except Exception as preprocess_error:
            return jsonify({
                'error': 'Image preprocessing failed',
                'message': str(preprocess_error)
            }), 400

        # Run inference with the TRAINED MODEL
        try:
            prediction = model.predict(preprocessed_image, verbose=0)
            prediction_value = prediction[0][0]  # Get scalar value

        except Exception as model_error:
            # If the model fails, return error (DO NOT use fallback)
            return jsonify({
                'error': 'AI model inference failed',
                'message': f'The trained model could not analyze the image: {str(model_error)}',
                'details': 'Check that the image format is compatible with the model'
            }), 500

        # Interpret results
        result, confidence, findings = interpret_prediction(prediction_value)

        return jsonify({
            'result': result,
            'confidence': round(confidence, 3),
            'findings': findings,
            'timestamp': datetime.now().isoformat(),
            'service': 'stroke_image_analysis',
            'model': 'keras_cnn',
            'source': 'trained_ai_model'
        })

    except Exception as e:
        return jsonify({
            'error': 'Server error',
            'message': str(e)
        }), 500

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5003))
    print(f"\n{'='*60}")
    print(f"ğŸ”¬ NeuroAid Stroke Image Analysis Service (REAL AI MODEL)")
    print(f"{'='*60}")
    print(f"ğŸ“ Running on: http://localhost:{port}")
    print(f"ğŸ“ Health check: http://localhost:{port}/health")
    print(f"ï¿½ï¿½ Analyze endpoint: POST http://localhost:{port}/analyze")
    print(f"ğŸ§  AI Model: {'LOADED âœ…' if MODEL_LOADED else 'NOT LOADED âŒ'}")
    print(f"{'='*60}\n")

    if not MODEL_LOADED:
        print("âš ï¸  WARNING: AI model not loaded. Service will return errors.")
        print(f"âš ï¸  Check that model file exists at: {MODEL_PATH}")
        print("âš ï¸  Expected file: stroke_image.keras\n")

    app.run(host='0.0.0.0', port=port, debug=True)
